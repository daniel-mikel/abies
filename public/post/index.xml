<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Abies</title>
    <link>/post/</link>
    <description>Recent content in Posts on Abies</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 16 Dec 2017 14:27:12 -0500</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Scraping Presidential Approval - Part 2</title>
      <link>/2017/12/scraping-presidential-approval---part-2/</link>
      <pubDate>Sat, 16 Dec 2017 14:27:12 -0500</pubDate>
      
      <guid>/2017/12/scraping-presidential-approval---part-2/</guid>
      <description>The other day I built my first web scraper for a single page. I ended the blogpost pretty satisfied with myself and thought I’d come back to the project at a later date to try to build my first web scraper to take all the presidential approval ratings from the site. I didn’t know how hard it would be at the time, and I was at the end of a long day at work.</description>
    </item>
    
    <item>
      <title>Scraping Presidential Approval</title>
      <link>/2017/12/scraping-presidential-approval/</link>
      <pubDate>Thu, 14 Dec 2017 21:19:12 -0500</pubDate>
      
      <guid>/2017/12/scraping-presidential-approval/</guid>
      <description>This is my first data scrapping project. I’ve taken a few tutorials in the past, but never really took the time to try out the technique. Data scrapping seems like a pretty handy tool to have in a world where people really don’t give a shit if you can use their data (and sometimes discourage it).
I’ve been pretty much addicted to 538 politics since at least 2012, but probably before that.</description>
    </item>
    
    <item>
      <title>California Wine  - Part 1</title>
      <link>/2017/11/california-wine----part-1/</link>
      <pubDate>Tue, 28 Nov 2017 21:13:14 -0500</pubDate>
      
      <guid>/2017/11/california-wine----part-1/</guid>
      <description>The United States Department of Agriculture publishes contract level price and volume data for California grapes crushed and used for wine. This allows us to see each purchase of a wine variety, what variety, it’s price, and the tonnage in the purchased amoung, giving us a disaggregated level data of data ripe for analysis. This is intended to be the first in a series of blog posts analysing the dynamics of the California.</description>
    </item>
    
    <item>
      <title>Cleaning Data</title>
      <link>/2017/11/cleaning-data/</link>
      <pubDate>Mon, 27 Nov 2017 21:13:14 -0500</pubDate>
      
      <guid>/2017/11/cleaning-data/</guid>
      <description>California Wine The first project I’m going to work on is with California Wine Grape Data. The data we’ll start with is hosted by the United States Department of Agriculture’s Grape Crush Report which collects wine price, production, and acreage for California by wine variety disaggregated to either the Grape Price District (this can mean one county or several counties) or the individual grape purchasing contract.
California Grape Price Districts Image</description>
    </item>
    
  </channel>
</rss>